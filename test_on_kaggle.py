"""
Test script for Kaggle - Run this in a Kaggle notebook cell after training.
Tests the model for ·∏Ö and √° character preservation before downloading.
"""

from huggingface_translator import IbaniHuggingFaceTranslator

def test_model_on_kaggle():
    """Test the trained model on Kaggle."""
    print("üß™ Testing Model on Kaggle")
    print("="*70)
    
    # Load the model from the output directory
    print("\nüìÇ Loading model from ./ibani_model...")
    translator = IbaniHuggingFaceTranslator(model_path="./ibani_model")
    
    # Test cases focusing on ·∏Ö and √°
    test_cases = [
        ("love", "·∏Ö·∫πl·∫πma"),  # Should contain ·∏Ö
        ("woman", "·ªçÃÅr·ª•ÃÅ·∏Ö·ªçÃÅ"),  # Should contain ·∏Ö
        ("she loves you", None),  # Check for spacing issues
        ("I love you", None),
        ("good morning", None),
        ("thank you", None),
    ]
    
    print("\nüìù Translation Tests:")
    print("-"*70)
    
    all_good = True
    
    for english, expected_ibani in test_cases:
        translation = translator.translate(english)
        
        # Check for spacing issues with ·∏Ö and √°
        has_space_issue = ' ·∏Ö ' in translation or ' √° ' in translation
        has_b = '·∏Ö' in translation
        has_a = '√°' in translation
        
        # Determine status
        if expected_ibani:
            matches = translation == expected_ibani
            status = "‚úÖ" if matches and not has_space_issue else "‚ö†Ô∏è"
        else:
            status = "‚úÖ" if not has_space_issue else "‚ö†Ô∏è"
        
        print(f"\n{status} EN: {english}")
        print(f"   IBANI: {translation}")
        
        if expected_ibani:
            print(f"   Expected: {expected_ibani}")
            if translation != expected_ibani:
                print(f"   ‚ö†Ô∏è  Mismatch!")
                all_good = False
        
        if has_space_issue:
            print(f"   ‚ùå SPACING ISSUE DETECTED!")
            all_good = False
        
        if has_b:
            print(f"   ‚úì Contains ·∏Ö")
        if has_a:
            print(f"   ‚úì Contains √°")
    
    # Test tokenization directly
    print("\n\nüîç Tokenization Tests:")
    print("-"*70)
    
    test_words = ['·∏Ö·∫πl·∫πma', '·ªçÃÅr·ª•ÃÅ·∏Ö·ªçÃÅ', '√°r·ªã', '·∏Ö', '√°']
    
    for word in test_words:
        tokens = translator.tokenizer.tokenize(word)
        decoded = translator.tokenizer.decode(
            translator.tokenizer.convert_tokens_to_ids(tokens),
            skip_special_tokens=True
        )
        
        preserved = (decoded.replace(' ', '') == word.replace(' ', ''))
        status = "‚úÖ" if preserved else "‚ùå"
        
        print(f"\n{status} Word: '{word}'")
        print(f"   Tokens: {tokens}")
        print(f"   Decoded: '{decoded}'")
        
        if not preserved:
            print(f"   ‚ùå Character loss detected!")
            all_good = False
    
    # Final verdict
    print("\n" + "="*70)
    if all_good:
        print("‚úÖ ALL TESTS PASSED!")
        print("‚úÖ Model is ready to download and deploy!")
        print("\nNo spacing issues detected with ·∏Ö and √° characters.")
    else:
        print("‚ö†Ô∏è  SOME TESTS FAILED")
        print("‚ö†Ô∏è  Review the output above before downloading.")
        print("\nYou may need to retrain with adjusted parameters.")
    
    print("\n" + "="*70)
    return all_good


# Run the test
if __name__ == "__main__":
    test_model_on_kaggle()
